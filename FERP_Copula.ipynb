{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVyJN64A99mIJA4jTjvQCZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dustoff06/FERP/blob/main/FERP_Copula.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4eqq4b9d38M",
        "outputId": "0dd3ab7e-8d20-471e-924b-d4aaf7e35894"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ Warning: Some rankings may contain too many ties!\n",
            "Estimated degrees of freedom: 30.00\n",
            "Joint Probability (T-Copula - Monte Carlo): 0.185494\n",
            "Conditional Marginals: {'P(U1 | U2, U3)': 0.4894346545421991, 'P(U2 | U1, U3)': 0.5052494789969144, 'P(U3 | U1, U2)': 0.49829944162025747}\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import multivariate_t, t, kurtosis\n",
        "\n",
        "def estimate_degrees_of_freedom(data, min_df=2, max_df=30):\n",
        "    \"\"\"\n",
        "    Estimate degrees of freedom from data using kurtosis matching.\n",
        "\n",
        "    The t-distribution's kurtosis is related to its degrees of freedom by:\n",
        "    kurt = 6/(df-4) for df > 4\n",
        "    We'll use this relationship to estimate df from empirical kurtosis.\n",
        "    \"\"\"\n",
        "    # Calculate kurtosis for each column\n",
        "    k = kurtosis(data, axis=0)\n",
        "\n",
        "    # Average kurtosis across columns\n",
        "    k_mean = np.mean(k)\n",
        "\n",
        "    # Solve for df using relationship between kurtosis and df\n",
        "    # If kurtosis is too low (< 0), default to high df\n",
        "    if k_mean <= 0:\n",
        "        return max_df\n",
        "\n",
        "    estimated_df = 6/k_mean + 4\n",
        "\n",
        "    # Bound the estimate\n",
        "    return np.clip(estimated_df, min_df, max_df)\n",
        "\n",
        "def nearest_positive_definite(matrix):\n",
        "    \"\"\"\n",
        "    Ensures the given matrix is positive definite by adjusting small eigenvalues.\n",
        "    \"\"\"\n",
        "    eigval, eigvec = np.linalg.eigh(matrix)\n",
        "    eigval[eigval < 1e-6] = 1e-6  # Adjust near-zero eigenvalues\n",
        "    return eigvec @ np.diag(eigval) @ eigvec.T\n",
        "\n",
        "def estimate_covariance(df, epsilon=1e-6):\n",
        "    \"\"\"\n",
        "    Computes the empirical correlation matrix from ranking data.\n",
        "    Standardizes each ranking column separately.\n",
        "    \"\"\"\n",
        "    # Standardize each column (ranking system) separately\n",
        "    standardized_rankings = (df - df.mean(axis=0)) / (df.std(axis=0, ddof=1) + epsilon)\n",
        "\n",
        "    # Compute correlation matrix\n",
        "    Sigma = np.corrcoef(standardized_rankings.T)\n",
        "\n",
        "    # Ensure positive definiteness\n",
        "    Sigma += np.eye(Sigma.shape[0]) * epsilon\n",
        "    if not np.all(np.linalg.eigvals(Sigma) > 0):\n",
        "        Sigma = nearest_positive_definite(Sigma)\n",
        "\n",
        "    return Sigma\n",
        "\n",
        "def rank_to_uniform(rankings):\n",
        "    \"\"\"\n",
        "    Convert rankings to uniform [0,1] variables using empirical CDF\n",
        "    \"\"\"\n",
        "    n = len(rankings)\n",
        "    return pd.Series(rankings).rank(method='average') / (n + 1)\n",
        "\n",
        "def t_copula_monte_carlo(rankings1, rankings2, rankings3, nu=None, num_samples=10000):\n",
        "    \"\"\"\n",
        "    Computes the t-copula joint probability using Monte Carlo approximation and\n",
        "    returns conditional marginals.\n",
        "\n",
        "    Parameters:\n",
        "    - rankings1, rankings2, rankings3: Raw ranking data\n",
        "    - nu: Degrees of freedom for the t-copula (if None, estimated from data)\n",
        "    - num_samples: Number of Monte Carlo samples\n",
        "\n",
        "    Returns:\n",
        "    - joint_prob: Approximate joint probability from Monte Carlo integration\n",
        "    - conditional_marginals: Dictionary of conditional probabilities\n",
        "    \"\"\"\n",
        "    # Create DataFrame of rankings\n",
        "    df_rankings = pd.DataFrame({\n",
        "        'rank1': rankings1,\n",
        "        'rank2': rankings2,\n",
        "        'rank3': rankings3\n",
        "    })\n",
        "\n",
        "    # Check for ties\n",
        "    n_items = len(rankings1)\n",
        "    if np.any(df_rankings.nunique() < n_items * 0.8):\n",
        "        print(\"⚠️ Warning: Some rankings may contain too many ties!\")\n",
        "\n",
        "    # Estimate degrees of freedom if not provided\n",
        "    if nu is None:\n",
        "        nu = estimate_degrees_of_freedom(df_rankings.values)\n",
        "        print(f\"Estimated degrees of freedom: {nu:.2f}\")\n",
        "\n",
        "    # Convert rankings to uniform variables using empirical CDF\n",
        "    U1 = rank_to_uniform(rankings1)\n",
        "    U2 = rank_to_uniform(rankings2)\n",
        "    U3 = rank_to_uniform(rankings3)\n",
        "\n",
        "    # Estimate correlation matrix from ranking data\n",
        "    Sigma = estimate_covariance(df_rankings)\n",
        "\n",
        "    # Generate samples from multivariate t-distribution\n",
        "    t_samples = multivariate_t.rvs(df=nu, shape=Sigma, size=num_samples)\n",
        "\n",
        "    # Transform t-samples to uniform using t-CDF\n",
        "    u_samples = t.cdf(t_samples, df=nu)\n",
        "\n",
        "    # Compute empirical joint CDF\n",
        "    joint_prob = np.mean(\n",
        "        (u_samples[:, 0] <= U1.values[:, None]) &\n",
        "        (u_samples[:, 1] <= U2.values[:, None]) &\n",
        "        (u_samples[:, 2] <= U3.values[:, None]),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # Convert uniform variables to t quantiles\n",
        "    t1 = t.ppf(U1, df=nu)\n",
        "    t2 = t.ppf(U2, df=nu)\n",
        "    t3 = t.ppf(U3, df=nu)\n",
        "\n",
        "    # Compute conditional probabilities\n",
        "    Sigma_23 = Sigma[1:, 1:]\n",
        "    Sigma_1_23 = Sigma[0, 1:]\n",
        "    Sigma_23_inv = np.linalg.inv(Sigma_23)\n",
        "\n",
        "    # Conditional means and variances in t-space\n",
        "    cond_mean_1 = Sigma_1_23 @ Sigma_23_inv @ np.vstack([t2, t3])\n",
        "    cond_var_1 = (Sigma[0, 0] - Sigma_1_23 @ Sigma_23_inv @ Sigma_1_23.T) * (nu + 2) / nu\n",
        "\n",
        "    cond_mean_2 = Sigma[1, [0, 2]] @ np.linalg.inv(Sigma[np.ix_([0, 2], [0, 2])]) @ np.vstack([t1, t3])\n",
        "    cond_var_2 = (Sigma[1, 1] - Sigma[1, [0, 2]] @ np.linalg.inv(Sigma[np.ix_([0, 2], [0, 2])]) @ Sigma[[0, 2], 1]) * (nu + 2) / nu\n",
        "\n",
        "    cond_mean_3 = Sigma[2, :2] @ np.linalg.inv(Sigma[:2, :2]) @ np.vstack([t1, t2])\n",
        "    cond_var_3 = (Sigma[2, 2] - Sigma[2, :2] @ np.linalg.inv(Sigma[:2, :2]) @ Sigma[:2, 2]) * (nu + 2) / nu\n",
        "\n",
        "    # Transform back to uniform space for conditional probabilities\n",
        "    cond_prob_1 = t.cdf(t1, df=nu, loc=cond_mean_1.T, scale=np.sqrt(cond_var_1))\n",
        "    cond_prob_2 = t.cdf(t2, df=nu, loc=cond_mean_2.T, scale=np.sqrt(cond_var_2))\n",
        "    cond_prob_3 = t.cdf(t3, df=nu, loc=cond_mean_3.T, scale=np.sqrt(cond_var_3))\n",
        "\n",
        "    conditional_marginals = {\n",
        "        \"P(U1 | U2, U3)\": cond_prob_1.mean(),\n",
        "        \"P(U2 | U1, U3)\": cond_prob_2.mean(),\n",
        "        \"P(U3 | U1, U2)\": cond_prob_3.mean()\n",
        "    }\n",
        "\n",
        "    return joint_prob, conditional_marginals\n",
        "\n",
        "# Example usage\n",
        "np.random.seed(42)\n",
        "n_items = 100\n",
        "\n",
        "# Generate rankings with some ties\n",
        "rankings1 = np.random.randint(1, n_items//2, n_items)  # Contains ties\n",
        "rankings2 = rankings1 + np.random.normal(0, 10, n_items)  # Correlated with rankings1\n",
        "rankings3 = np.random.permutation(n_items) + 1  # No ties\n",
        "\n",
        "# Compute joint probability and conditional marginals with adaptive df\n",
        "joint_prob, conditional_marginals = t_copula_monte_carlo(rankings1, rankings2, rankings3)\n",
        "\n",
        "print(f\"Joint Probability (T-Copula - Monte Carlo): {joint_prob.mean():.6f}\")\n",
        "print(\"Conditional Marginals:\", conditional_marginals)"
      ]
    }
  ]
}